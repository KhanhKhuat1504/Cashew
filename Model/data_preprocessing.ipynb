{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505a2d45-aa88-470b-b5b2-2dde2885f376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58d66d60-c60b-4d7f-a366-a8ff4349a63a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the base directory where sub1 to sub10 folders are located\n",
    "BASE_DIR = \"C:\\\\Users\\\\lankh\\\\Downloads\\\\SFU-IMU Dataset\\IMU Dataset\"  # Replace with the actual path to your dataset\n",
    "\n",
    "# Define the subjects (sub1 to sub10)\n",
    "subjects = [f'sub{i}' for i in range(1, 11)]\n",
    "\n",
    "# Define the activity categories\n",
    "categories = ['ADLs', 'Falls', 'Near_Falls']\n",
    "\n",
    "# Define the columns to select\n",
    "selected_columns = [\n",
    "    'waist Acceleration X (m/s^2)',\n",
    "    'waist Acceleration Y (m/s^2)',\n",
    "    'waist Acceleration Z (m/s^2)',\n",
    "    'waist Angular Velocity X (rad/s)',\n",
    "    'waist Angular Velocity Y (rad/s)',\n",
    "    'waist Angular Velocity Z (rad/s)'\n",
    "]\n",
    "\n",
    "# Sampling frequency of the IMU data (Hz)\n",
    "SAMPLING_FREQUENCY = 50  # Adjust if different\n",
    "\n",
    "# Low-pass filter configuration\n",
    "CUTOFF_FREQUENCY = 5  # Hz\n",
    "FILTER_ORDER = 4\n",
    "\n",
    "# Output path for the preprocessed data\n",
    "OUTPUT_FILE = os.path.join(BASE_DIR, 'preprocessed_imu_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "636d9b4a-067e-4c4b-98f2-da035f643212",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and filtering data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Subjects: 100%|████████████████████████████████████████████████████████████████████████| 10/10 [10:00<00:00, 60.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data points before preprocessing: 1190369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize a list to hold all DataFrames\n",
    "data_frames = []\n",
    "\n",
    "# Iterate through each subject\n",
    "print(\"Loading and filtering data...\")\n",
    "for subject in tqdm(subjects, desc='Subjects'):\n",
    "    subject_path = os.path.join(BASE_DIR, subject)\n",
    "    \n",
    "    # Iterate through each activity category\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(subject_path, category)\n",
    "        \n",
    "        # Check if the category directory exists\n",
    "        if not os.path.isdir(category_path):\n",
    "            print(f\"Warning: Directory {category_path} does not exist. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Iterate through each .xlsx file in the category directory\n",
    "        for file_name in os.listdir(category_path):\n",
    "            if file_name.endswith('.xlsx'):\n",
    "                file_path = os.path.join(category_path, file_name)\n",
    "                \n",
    "                try:\n",
    "                    # Read the Excel file\n",
    "                    df = pd.read_excel(file_path)\n",
    "                    \n",
    "                    # Select the desired columns\n",
    "                    df_selected = df[selected_columns].copy()\n",
    "                    \n",
    "                    # Add labels for activity and subject\n",
    "                    df_selected['Activity'] = category\n",
    "                    df_selected['Subject'] = subject\n",
    "                    \n",
    "                    # Append the DataFrame to the list\n",
    "                    data_frames.append(df_selected)\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "if data_frames:\n",
    "    data = pd.concat(data_frames, ignore_index=True)\n",
    "    print(f\"Total data points before preprocessing: {len(data)}\")\n",
    "else:\n",
    "    raise ValueError(\"No data was loaded. Please check the dataset path and folder structure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7826bc86-b711-4f90-b4a4-67d3640c3462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def low_pass_filter(data, cutoff, fs, order=4):\n",
    "    \"\"\"\n",
    "    Apply a low-pass Butterworth filter to the data.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: pandas DataFrame containing the data to filter\n",
    "    - cutoff: cutoff frequency in Hz\n",
    "    - fs: sampling frequency in Hz\n",
    "    - order: order of the Butterworth filter\n",
    "    \n",
    "    Returns:\n",
    "    - Filtered pandas DataFrame\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    # Get the filter coefficients\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    \n",
    "    # Apply the filter to each selected column\n",
    "    for column in selected_columns:\n",
    "        data[column] = filtfilt(b, a, data[column])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b757a526-9cea-4f53-9aa8-e2fd37ec43ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing...\n",
      "Data points after handling missing values: 1190369\n",
      "Preprocessed data saved to C:\\Users\\lankh\\Downloads\\SFU-IMU Dataset\\IMU Dataset\\preprocessed_imu_data.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting preprocessing...\")\n",
    "\n",
    "# 1. Handle Missing Values\n",
    "# Option 1: Drop rows with any missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Option 2: Alternatively, fill missing values (uncomment if preferred)\n",
    "# data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "print(f\"Data points after handling missing values: {len(data)}\")\n",
    "\n",
    "# 2. Apply Low-Pass Filter to Remove High-Frequency Noise\n",
    "data = low_pass_filter(data, CUTOFF_FREQUENCY, SAMPLING_FREQUENCY, FILTER_ORDER)\n",
    "\n",
    "# 3. Standardize the Data\n",
    "scaler = StandardScaler()\n",
    "data[selected_columns] = scaler.fit_transform(data[selected_columns])\n",
    "\n",
    "# 4. Encode Activity Labels\n",
    "label_encoder = LabelEncoder()\n",
    "data['Activity_Label'] = label_encoder.fit_transform(data['Activity'])\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Save Preprocessed Data\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Save the preprocessed data to a CSV file\n",
    "data.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"Preprocessed data saved to {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61d75f2-439d-4a1f-a7a8-b5dbe91ccc54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
